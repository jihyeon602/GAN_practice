{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습1] 구조를 개선한 GAN 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습목표\n",
    "1. Vanilla GAN의 구조를 개선하여 성능이 향상된 모델의 종류를 학습합니다.\n",
    "\n",
    "2. 다양한 GAN 모델의 특징을 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    "1. DCGAN\n",
    "2. cGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN은 2014년 Ian Goodfellow가 발표한 이후 다양한 구조로 발전해 왔습니다. 이번 실습에서는 현재까지 발표된 GAN 모델 중 일부의 구조와 생성 결과에 대해 직접 실행하며 알아봅니다.\n",
    "\n",
    "첫 번째로 알아볼 모델은 **DCGAN**(**D**eep **C**onvolutional **G**enerative **A**dversarial **N**etworks)입니다. **DCGAN**은 기본적인 GAN(Vanilla GAN)과 달리 CNN 기법을 사용하여 이미지의 구조적 특징을 더 효과적으로 학습합니다.\n",
    "\n",
    "- `합성곱 신경망 구조(Convolutional Neural Network)` : DCGAN은 합성곱 레이어를 사용하여 이미지 데이터에 대한 학습을 진행합니다.\n",
    "- `배치 정규화(Batch Normalization)` : DCGAN은 모든 레이어에 배치 정규화를 적용하여 학습의 안정성을 높이고, 학습 속도를 빠르게 만들어 줍니다.\n",
    "- `완전 연결 층(Fully Connected Layer) 제거` : DCGAN은 이미지 생성 과정에서 전통적인 완전 연결 층 대신에 전치 합성곱 층을 사용하여 고해상도의 이미지를 생성할 수 있습니다.\n",
    "- `활성화 함수(Activation fucntions)` : DCGAN에서는 LeakyReLU 활성화 함수를 주로 사용하여 기울기 소실 문제를 완화합니다. 또한, 생성자의 마지막 레이어에서는 tanh 활성화 함수를 사용해 -1과 1 사이의 출력 범위를 갖게 합니다.\n",
    "\n",
    "최근에 발표한 대부분의 GAN모델은 DCGAN 기반의 GAN 모델인 경우가 많습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/DCGAN_Structure.png\" style=\"width: 800px\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import RandomSampler, DataLoader, Dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# 학습이 진행되는 과정을 확인하기 위해 고정된 SEED를 설정합니다\n",
    "seed = random.randint(1, 10000) \n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용하는 데이터는 [Celeba 데이터](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)로 20만 개 이상의 유명인 얼굴 이미지 데이터 세트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋의 경로\n",
    "dataroot = r\"C:\\lsc\\GAN\\celba\"\n",
    "\n",
    "# dataloader에서 사용할 스레드 수\n",
    "workers = 2\n",
    "\n",
    "# 배치 크기\n",
    "batch_size = 128\n",
    "\n",
    "# 이미지 크기\n",
    "image_size = 64\n",
    "\n",
    "# 이미지의 채널 수 (컬러 이미지이기 때문에 3으로 설정)\n",
    "nc = 3\n",
    "\n",
    "# 잠재공간 벡터의 크기\n",
    "nz = 100\n",
    "\n",
    "# 생성자를 통과하는 특징 데이터들의 채널 크기\n",
    "ngf = 64\n",
    "\n",
    "# 판별자를 통과하는 특징 데이터들의 채널 크기\n",
    "ndf = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 데이터 세트 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset`와 `dataloader`를 설정하여 데이터 세트를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset을 설정합니다\n",
    "# image_size로 이미지의 크기를 조정하고 이미지를 [-1, 1] 범위로 정규화합니다\n",
    "dataset = dset.ImageFolder(\n",
    "    root=dataroot,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 학습에 사용될 데이터의 갯수를 5000개로 설정합니다.\n",
    "sampler = RandomSampler(dataset, replacement=False, num_samples=5000)\n",
    "\n",
    "# dataloader를 설정합니다\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler = sampler, shuffle=False, num_workers=workers\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용하는 이미지를 dataloader를 통해 불러와 확인해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(\n",
    "            real_batch[0].to(device)[:64], padding=2, normalize=True\n",
    "        ).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 가중치 초기화\n",
    "\n",
    "DCGAN의 저자들이 추천하는 정규분포를 사용하여 생성자와 판별자를 초기화합니다. \n",
    "- **평균** : 0(`mean = 0`)\n",
    "- **분산** : 0.01(`stdev = 0.02`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 생성자\n",
    "DCGAN의 생성자는 잠재 공간 벡터 z를 입력받아 이미지를 생성하는 네트워크입니다. 네트워크의 각 층은 **전치 합성곱 층**으로 구성되어 있으며 스트라이드는 2, 활성화 함수로는 **ReLU**를 사용합니다. 마지막 출력층에서는 **tanh** 함수를 사용하여 출력 값을 -1에서 1 사이의 값으로 조정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # 입력층\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "           \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "        \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 출력층\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Generator`클래스를 사용해서 생성자를 만들어볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(1).to(device)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 판별자\n",
    "\n",
    "DCGAN의 판별자는 입력 이미지의 진짜, 가짜 여부를 판별하는 네트워크입니다. 판별자의 마지막 출력층에서 **Sigmoid**함수를 사용하여 **0에서 1 사이**의 값으로 조정합니다. 이때 0에 가까울수록 가짜 이미지로 판별한 것이고, 1에 가까울수록 진짜 이미지로 판별한 것을 의미합니다. 판별자는 활성화 함수로 LeakyReLU를 사용해서 Vanilla GAN의 기울기 소실 문제를 해결했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # 입력층\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 출력층\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성자와 마찬가지로 `Discriminator` 클래스를 사용해서 판별자를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator(1).to(device)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 손실함수와 옵티마이저\n",
    "\n",
    "이제 손실함수와 옵티마이저를 설정합니다. DCGAN은 손실함수로 `Binary Cross Entropy loss`를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저의 학습률\n",
    "lr = 0.0002\n",
    "\n",
    "# Adam 옵티마이저의 beta1 하이퍼파라미터\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `BCELoss` 함수의 인스턴스를 초기화합니다\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 생성자의 학습상태를 확인할 잠재 공간 벡터를 생성합니다\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# 실제 이미지일 경우 1, 가짜 이미지일 경우 0으로 설정합니다\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "# G와 D에서 사용할 Adam옵티마이저를 생성합니다\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 학습\n",
    "\n",
    "이제 위에서 생성한 생성자, 판별자와 손실함수, 옵티마이저를 사용해서 학습을 진행하고 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할 에폭 수\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습상태를 체크하기 위해 손실값들을 저장합니다\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Starting epoch {}...\".format(epoch))\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############\n",
    "        # 판별자 학습 #\n",
    "        ############\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "        # 실제 이미지를 판별자에 입력합니다\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # 손실값을 구합니다\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # 생성자에 사용할 잠재공간 벡터(노이즈)를 생성합니다\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # 생성자에 노이즈를 입력하여 이미지를 생성합니다\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # 생성된 이미지를 판별자에 입력합니다\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # 손실값을 구합니다\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        # 생성된 이미지와 실제 이미지에서 구한 손실값을 더합니다\n",
    "        errD = errD_real + errD_fake\n",
    "        # 판별자를 업데이트 합니다\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############\n",
    "        # 생성자 학습 #\n",
    "        ############\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        # 판별자에 생성된 이미지를 입력합니다\n",
    "        output = netD(fake).view(-1)\n",
    "        # 생성자의 손실값을 구합니다\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # 생성자를 업데이트 합니다\n",
    "        optimizerG.step()\n",
    "\n",
    "        ###############\n",
    "        # 훈련 상태를 출력#\n",
    "        ###############\n",
    "        if i % 50 == 0:\n",
    "            print(\n",
    "                \"[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    num_epochs,\n",
    "                    errD.item(),\n",
    "                    errG.item(),\n",
    "                    D_x,\n",
    "                    D_G_z1,\n",
    "                    D_G_z2,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # 고정해둔 SEED값을 사용하여 모델이 학습하는 과정을 확인합니다\n",
    "        if (iters % 500 == 0) or (\n",
    "            (epoch == num_epochs - 1) and (i == len(dataloader) - 1)\n",
    "        ):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 완료되었다면 결과를 확인해볼까요? 생성자와 판별자의 Loss 변화를 그래프를 통해 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번엔 모델이 생성한 이미지를 epoch가 진행됨에 따라 달라지는 것을 살펴볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만족스러운 결과인가요? DCGAN은 실습 처음에 말씀드렸듯이 이후의 GAN 모델의 기본이 되는 모델입니다. 이후 실습을 통해 GAN 모델의 발전을 살펴봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CGAN\n",
    "\n",
    "Vanilla GAN은 무작위 노이즈(z)를 입력받아 데이터를 생성하는 모델입니다. CGAN(Conditional Generative Adversarial Networks)은 **추가적인 조건이나 정보**(Condition)를 노이즈와 함께 입력받아 데이터 생성하는 모델입니다. 이때 Contidion은 원하는 특성이나 레이블을 의미합니다. 생성자는 이 Condition에 맞고 실제와 비슷한 데이터를 생성하는 것을 목표로 하고, 판별자는 생성된 이미지가 실제 이미지인지와 더불이 Condition에 맞는 데이터인지 판별합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/CGAN.png\" style=\"width: 400px\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 데이터 세트 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용하는 데이터는 Fashion MNIST 데이터입니다. Fashion MNIST는 MNIST 데이터 세트를 보완하기 위해 만들어진 데이터 세트로 패션 제품의 이미지 70,000장으로 이루어져 있습니다. 각 이미지는 28x28 픽셀의 흑백 이미지로, 10개의 클래스(티셔츠, 바지, 재킷, 드레스, 코트, 샌달, 셔츠, 스니커즈, 가방,앵클 부트)에 따라 이미지를 분류합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Fashion_MNIST.png\" style=\"width: 600px\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNIST(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        fashion_df = pd.read_csv(\"./fashion-mnist_train.csv\")\n",
    "        self.labels = fashion_df.label.values\n",
    "        self.images = fashion_df.iloc[:, 1:].values.astype(\"uint8\").reshape(-1, 28, 28)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img = Image.fromarray(self.images[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNIST 데이터 세트를 한번 살펴볼까요? 데이터 세트의 첫 번째 이미지를 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x1DBC4F9F9B0>, 2)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APH/AAh4P1Lxnq5sNPMcYjTzJp5c7I16c4BJJPAHf6ZI9Lm+ADRvarFr3nKz4uG+zhNi+qgv83pjIPT3xieOPg3d+GdJl1jTL8ahYw8zxtHsmiUnG7AJDKMjJGCM9MZNeX19IfBrQjpPgcXjoFudUk84k8HylyqA/wDj7D/frsp5tXWacQWtm0YYCFnm5Zeck88HpxVyOJrmyaO/hgcSo0Usa8o6MMEYOeCCRXyd4y8PP4W8WX+kEs0UMm6Bz/HE3zIfrtIz75HavdPA3xI0XX59N8P2NndW1wloUVZduwCGLICkHLEhT2HAJr0AK69FcexU4rA8a+Im8K+FptXSLzJIZ4AImO0SguAyE44ym7kcggHsa8H8cePLLxXry3qaJH5UUIgjNzIxcqGZsnaQB948c/WuKtrq4srhLi0nlgnTlJYnKsvbgjkVojxR4gHTXdT/APAuT/Gq15rOqahEIr3Ury5jDbgk07OAeRnBPXk/nVKv/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACH0lEQVR4AbVSPWtUQRS98/G+dtmnZhM/ovgRERGRNKkUUqiFoGgV0B+gjUIEWwutgrVok0otU6u12hhRIhEkUdSshmASzSabzZs3M3fmOi9i4Q/IGZhhzuHcGc69AFsCVlWVWO3DNJOafSNPX1WX/3B5cr5Ft4bv0fJXGvunbDph8N2K7CjIx87tTWpJTzT4YVMPIiP4mHZFnZViYLnDMfbNnFcscAYEd3at5fW2csX0El/nRfSj/TCwwQbcw+81XQrOdEqMXESlbh7J1wPPwxpRXaEZFhmidQKxntifj8FXToDZRCmiRqPUWWYlYjsSfvvJlkTGqO/tOqg0n3vjTr3P2hsDh/tXG7o5eSl8iOAasxQb8WXqm1KvV5rYEczg6sUGsFD2u27Hnupz8+b4opG9Pm86B37nxI3w5olnizWXSMqoLOuZNsQFGZ3aYxwk3CTSUsXFYsZ0F2MeuZiBtPbX9QcMlpdUQiQ3bFLnSB5jlSaODGuk/Xyo16ATzMU13ymFjGs8M66TQ1R09/DTn0wM4K0XGStUqY320f6X9we7qucKmzizoHYgK72PmPVccGlxW18+V8Opq/z2k42hF+OHFDDHa5wcqogBwsHp0fMLcnYUDrTuiiLhYDGqEnUmeg5wNuQqQ/gtmGFZqSVnnIU4gbAAAUC+ara0QJ/TGNF7Ai+p3H3rUfD87Uo4xo8uBB/E3jtC07wQBqEaha3BH4BNEQZhnoQBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = FashionMNIST()\n",
    "print(dataset[0])\n",
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 불러온 이미지와 같이 Fashion MNIST 데이터 세트는 10개의 클래스로 분류되는 흑백 의류 이미지입니다.\n",
    "\n",
    "DCGAN에서와 비슷하게 이 데이터 세트를 모델 학습에 적합한 형태로 변환하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, ), std=(0.5, ))\n",
    "])\n",
    "dataset = FashionMNIST(transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 생성자\n",
    "\n",
    "DCGAN의 생성자와 가장 큰 차이점은 노이즈 뿐만 아니라 `label`을 입력 받아 학습에서 사용한다는 점입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # label을 임베딩합니다. (10개의 클래 스를 10차원의 벡터로)\n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "\n",
    "        # 모델 구조\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        z = z.view(z.size(0), 100)\n",
    "        c = self.label_emb(labels)\n",
    "        \n",
    "        # 노이즈(z)와 label(c)를 연결하여 생성자가 이미지생성시 label도 사용하도록 합니다.\n",
    "        x = torch.cat([z, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.view(x.size(0), 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 판별자\n",
    "\n",
    "생성자와 마찬가지로 판별자 역시 입력으로 이미지 데이터와 `label`을 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # label을 임베딩합니다. (10개의 클리스를 10차원의 벡터로)\n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "\n",
    "        # 모델 구조\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        x = x.view(x.size(0), 28*28)\n",
    "        c = self.label_emb(labels)\n",
    "        \n",
    "        # 입력받은 이미지(x)와 label(c)를 연결합니다.\n",
    "        x = torch.cat([x, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 손실함수와 옵티마이저\n",
    "\n",
    "이제 손실함수와 옵티마이저를 설정합니다. CGAN은 손실함수로 `Binary Cross Entropy loss`를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 학습\n",
    "\n",
    "이제 위에서 정의한 생성자, 판별자, 그리고 손실함수와 옵티마이저를 사용해서 CGAN을 학습해 보도록 하겠습니다. `generator_train_step`함수와 `discriminator_train_step`함수는 각각 생성자와 판별자의 학습 단계를 구현한 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
    "    g_optimizer.zero_grad()\n",
    "    z = Variable(torch.randn(batch_size, 100)).cuda()\n",
    "    fake_labels = Variable(\n",
    "        torch.LongTensor(np.random.randint(0, 10, batch_size))\n",
    "    ).cuda()\n",
    "    \n",
    "    # 노이즈(z)와 라벨(fake_labels)를 통해 이미지를 생성합니다.\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # 생성한 이미지를 판별자에 입력합니다.\n",
    "    validity = discriminator(fake_images, fake_labels)\n",
    "    \n",
    "    # 손실값을 구합니다.\n",
    "    g_loss = criterion(validity, Variable(torch.ones(batch_size)).cuda())\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train_step(\n",
    "    batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels\n",
    "):\n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    # 실제 이미지를 판별자에 입력합니다.\n",
    "    real_validity = discriminator(real_images, labels)\n",
    "    real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).cuda())\n",
    "\n",
    "    # 생성한 이미지를 판별자에 입력합니다.\n",
    "    z = Variable(torch.randn(batch_size, 100)).cuda()\n",
    "    fake_labels = Variable(\n",
    "        torch.LongTensor(np.random.randint(0, 10, batch_size))\n",
    "    ).cuda()\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    fake_validity = discriminator(fake_images, fake_labels)\n",
    "    fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).cuda())\n",
    "\n",
    "    # 실제 이미지와 생성한 이미지의 손실값을 더합니다.\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    return d_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 실제로 학습을 진행해 보겠습니다. 학습에는 10~15분정도 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "n_critic = 5\n",
    "display_step = 300\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Starting epoch {}...\".format(epoch))\n",
    "    for i, (images, labels) in tqdm(enumerate(data_loader)):\n",
    "        real_images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        generator.train()\n",
    "        batch_size = real_images.size(0)\n",
    "        d_loss = discriminator_train_step(\n",
    "            len(real_images),\n",
    "            discriminator,\n",
    "            generator,\n",
    "            d_optimizer,\n",
    "            criterion,\n",
    "            real_images,\n",
    "            labels,\n",
    "        )\n",
    "\n",
    "        g_loss = generator_train_step(\n",
    "            batch_size, discriminator, generator, g_optimizer, criterion\n",
    "        )\n",
    "\n",
    "    generator.eval()\n",
    "    print(\"g_loss: {}, d_loss: {}\".format(g_loss, d_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤가요? 꽤 만족스러운 결과를 얻을 수 있습니다.\n",
    "\n",
    "하지만 CGAN에서 중요한 점은 실제 이미지와 유사한 이미지를 생성하는 것 외에도 조건(Condition)에 맞는 이미지를 생성하는 것입니다. 아래 코드를 실행하여 조건에 맞는 이미지를 생성하는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(torch.randn(100, 100)).cuda()\n",
    "labels = Variable(torch.LongTensor([i for _ in range(10) for i in range(10)])).cuda()\n",
    "sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
    "grid = make_grid(sample_images, nrow=10, normalize=True).permute(1, 2, 0).numpy()\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.imshow(grid)\n",
    "_ = plt.yticks([])\n",
    "_ = plt.xticks(\n",
    "    np.arange(15, 300, 30),\n",
    "    [\n",
    "        \"T-Shirt\",\n",
    "        \"Trouser\",\n",
    "        \"Pullover\",\n",
    "        \"Dress\",\n",
    "        \"Coat\",\n",
    "        \"Sandal\",\n",
    "        \"Shirt\",\n",
    "        \"Sneaker\",\n",
    "        \"Bag\",\n",
    "        \"Ankle boot\",\n",
    "    ],\n",
    "    rotation=45,\n",
    "    fontsize=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 카테고리별로 유사한 형태를 띄는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
